
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dating-deploy
spec:
  replicas: 1
  minReadySeconds: 5
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: dating-container
  template:
    metadata:
      name: dating-deploy
      labels:
        app: dating-container
      annotations:
        changeRollingUpdate: ${K8S_datinga}
    spec:
      restartPolicy: Always
      terminationGracePeriodSeconds: 10
      volumes:
        - name: sqlite-data
          hostPath:
            type: DirectoryOrCreate
            path: /var/www/k8s/data/tmp/dating/tmp/
        - name: static
          hostPath:
            type: DirectoryOrCreate
            path: /var/www/k8s/data/tmp/dating/static/
        - name: log
          persistentVolumeClaim:
            claimName: log
        - name: config
          configMap:
            name: dating-config
      containers:
        - name: dating-container
          image: ghcr.io/twbworld/dating:1.0.1
          imagePullPolicy: IfNotPresent
          ports:
            - name: cp
              containerPort: 80
          env:
            - name: TZ
              valueFrom:
                configMapKeyRef:
                  name: global
                  key: timezone
            - name: UUID
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.uid
          volumeMounts:
            - name: sqlite-data
              mountPath: /app/tmp/
            - name: static
              mountPath: /app/static/
            - name: config
              mountPath: /volume/config/
            - name: log
              mountPath: /app/log/
              subPathExpr: dating-$(UUID)
          command:
            - /bin/sh
            - -c
            - |
              ./server -c /volume/config/config.yaml
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            httpGet:
              scheme: HTTP
              port: cp
              path: /
          resources:
            requests:
              memory: 128Mi
              cpu: 500m
            limits:
              memory: 160Mi
              cpu: 750m

---
apiVersion: v1
kind: Service
metadata:
  name: dating-svc
spec:
  selector:
    app: dating-container
  type: ClusterIP
  sessionAffinity: ClientIP
  ports:
    - name: sp
      port: 80


---
#自动扩缩
#https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.13/html/nodes/nodes-pods-autoscaling
#压力测试: kubectl run --rm -it --image=busybox:latest --restart=Never test -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://dating-svc:80/test.html; done"
#需要给容器定义resources配置
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-dating
status:
  observedGeneration: 1
  # lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
      current:
        averageUtilization: 0
        averageValue: 0
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: dating-deploy
  minReplicas: 1
  maxReplicas: 2 #最大的pod的数量
  metrics:
  - type: Resource
    resource:
      name: cpu
      target: #当pod的[name]使用率达到[resources.requests]的[averageUtilization]%时进行扩容
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0 # 需要扩容时，立即扩容
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容数量为当前Pod数量的[value]%
      - type: Pods
        value: 1
        periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容[value]个 Pod
      selectPolicy: Max # 使用以上两种扩容策略中算出来扩容 Pod 数量最大的
    scaleDown:
      stabilizationWindowSeconds: 300 # 需要缩容时，先观察[stabilizationWindowSeconds]秒，如果一直持续需要缩容才执行缩容
      policies:
      - type: Percent
        value: 100 # 允许缩掉[value]%的pod
        periodSeconds: 15
