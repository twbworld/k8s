---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: proxy-deploy
spec:
  replicas: 1
  minReadySeconds: 5
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: proxy-container
  template:
    metadata:
      name: proxy-deploy
      labels:
        app: proxy-container
    spec:
      restartPolicy: Always
      terminationGracePeriodSeconds: 10
      volumes:
        - name: sqlite-data
          hostPath:
            type: DirectoryOrCreate
            path: /var/www/k8s/data/tmp/proxy/tmp/
        - name: log
          persistentVolumeClaim:
            claimName: log
        - name: config
          configMap:
            name: proxy-config
      # initContainers: #https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/init-containers/
      #   - name: wait-mysql #检测mysql存活,配置启动顺序
      #     image: mysql:8.0-debian
      #     imagePullPolicy: IfNotPresent
      #     env:
      #       - name: MYSQL_ROOT_PASSWORD
      #         valueFrom:
      #           secretKeyRef:
      #             name: mysql-secret
      #             key: root-pwd
      #     command:
      #       - sh
      #       - -c
      #       - |-
      #         set -e
      #         maxTries=15
      #         while [ $maxTries -gt 0 ] && ! mysqladmin ping --connect-timeout=3 -s -hmysql-svc -uroot -p$MYSQL_ROOT_PASSWORD;do
      #             echo '等待mysql可用'
      #             sleep 1
      #             maxTries=$(( $maxTries - 1 ))
      #         done
      #         if [ $maxTries -le 0 ]; then
      #             echo >&2 'error: 尝试多次连接mysql服务失败'
      #             exit 1
      #         fi
      #         echo 'mysql已启动'
      #     resources:
      #       requests:
      #         memory: 32Mi
      #         cpu: 50m
      #       limits:
      #         memory: 512Mi
      #         cpu: 1
      containers:
        - name: proxy-container
          image: ghcr.io/twbworld/proxy:1.4.6
          imagePullPolicy: IfNotPresent
          ports:
            - name: cp
              containerPort: 80
          env:
            - name: TZ
              valueFrom:
                configMapKeyRef:
                  name: global
                  key: timezone
                  optional: true
            - name: UUID
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.uid
          volumeMounts:
            - name: sqlite-data
              mountPath: /app/tmp/
            - name: config
              mountPath: /volume/config/
            - name: log
              mountPath: /app/log/
              subPathExpr: proxy-$(UUID)
          command:
            - /bin/sh
            - -c
            - |
              ./server -c /volume/config/config.yaml
              # ln -sf /volume/config/config.yaml /app/config.yaml #k8s单文件挂载内容不能同步,所以使用"挂载目录"+"软连接"解决
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            httpGet:
              scheme: HTTP
              port: cp
              path: /
          livenessProbe:
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 3
            httpGet:
              scheme: HTTP
              port: cp
              path: /
          resources:
            requests:
              memory: 80Mi
              cpu: 100m
            limits:
              memory: 256Mi
              cpu: 500m

---
apiVersion: v1
kind: Service
metadata:
  name: proxy-svc
spec:
  selector:
    app: proxy-container
  type: ClusterIP
  sessionAffinity: ClientIP
  ports:
    - name: sp
      port: 80

---
#自动扩缩
#https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.13/html/nodes/nodes-pods-autoscaling
#压力测试: kubectl run --rm -it --image=busybox:latest --restart=Never test -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://proxy-svc:80/test.html; done"
#需要给容器定义resources配置
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-proxy
status:
  observedGeneration: 1
  # lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
    - type: Resource
      resource:
        name: cpu
        current:
          averageUtilization: 0
          averageValue: 0
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: proxy-deploy
  minReplicas: 1
  maxReplicas: 2 #最大的pod的数量
  metrics:
    - type: Resource
      resource:
        name: cpu
        target: #当pod的[name]使用率达到[resources.requests]的[averageUtilization]%时进行扩容
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0 # 需要扩容时，立即扩容
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容数量为当前Pod数量的[value]%
        - type: Pods
          value: 1
          periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容[value]个 Pod
      selectPolicy: Max # 使用以上两种扩容策略中算出来扩容 Pod 数量最大的
    scaleDown:
      stabilizationWindowSeconds: 300 # 需要缩容时，先观察[stabilizationWindowSeconds]秒，如果一直持续需要缩容才执行缩容
      policies:
        - type: Percent
          value: 100 # 允许缩掉[value]%的pod
          periodSeconds: 15
