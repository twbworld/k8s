---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: proxy-deploy
  labels:
    app: proxy
spec:
  replicas: 1
  revisionHistoryLimit: 2
  minReadySeconds: 10
  strategy:
    type: Recreate #避免SQLite锁问题, 不使用RollingUpdate
  selector:
    matchLabels:
      app: proxy
  template:
    metadata:
      labels:
        app: proxy
    spec:
      priorityClassName: normal-pc
      terminationGracePeriodSeconds: 30
      restartPolicy: Always
      volumes:
        - name: sqlite-data
          hostPath:
            type: DirectoryOrCreate
            path: /var/www/k8s/data/tmp/proxy/tmp/
        - name: cm
          configMap:
            name: proxy-cm
      containers:
        - name: proxy-server
          image: ghcr.io/twbworld/proxy:1.5.0
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              memory: 48Mi
              cpu: 20m
            limits:
              memory: 128Mi
              cpu: 400m
          ports:
            - name: cp
              containerPort: 80
          env:
            - name: TZ
              value: Asia/Shanghai
          volumeMounts:
            - name: sqlite-data
              mountPath: /app/tmp/
            - name: cm
              mountPath: /volume/config/
          command:
            - /bin/sh
            - -c
            - |
              ./server -c /volume/config/config.yaml
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            httpGet:
              scheme: HTTP
              port: cp
              path: /
          livenessProbe:
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 3
            httpGet:
              scheme: HTTP
              port: cp
              path: /
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c", "sleep 5"]

---
apiVersion: v1
kind: Service
metadata:
  name: proxy-svc
  labels:
    app: proxy
spec:
  type: ClusterIP
  sessionAffinity: ClientIP
  selector:
    app: proxy
  ports:
    - name: sp
      port: 80

---
#自动扩缩
#https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.13/html/nodes/nodes-pods-autoscaling
#压力测试: kubectl run --rm -it --image=busybox:latest --restart=Never test -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://proxy-svc:80/test.html; done"
#需要给容器定义resources配置
# apiVersion: autoscaling/v2
# kind: HorizontalPodAutoscaler
# metadata:
#   name: hpa-proxy
# spec:
#   scaleTargetRef:
#     apiVersion: apps/v1
#     kind: Deployment
#     name: proxy-deploy
#   minReplicas: 1
#   maxReplicas: 2 #最大的pod的数量
#   metrics:
#     - type: Resource
#       resource:
#         name: cpu
#         target: #当pod的[name]使用率达到[resources.requests]的[averageUtilization]%时进行扩容
#           type: Utilization
#           averageUtilization: 80
#   behavior:
#     scaleUp:
#       stabilizationWindowSeconds: 0 # 需要扩容时，立即扩容
#       policies:
#         - type: Percent
#           value: 100
#           periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容数量为当前Pod数量的[value]%
#         - type: Pods
#           value: 1
#           periodSeconds: 15 # 每[periodSeconds]秒最大允许扩容[value]个 Pod
#       selectPolicy: Max # 使用以上两种扩容策略中算出来扩容 Pod 数量最大的
#     scaleDown:
#       stabilizationWindowSeconds: 300 # 需要缩容时，先观察[stabilizationWindowSeconds]秒，如果一直持续需要缩容才执行缩容
#       policies:
#         - type: Percent
#           value: 100 # 允许缩掉[value]%的pod
#           periodSeconds: 15
